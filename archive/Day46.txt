Day-46


## quiz_02.py

import urllib.request
from bs4 import BeautifulSoup
import pandas as pd
from pandas import DataFrame
import matplotlib.pyplot as plt

plt.rcParams['font.family'] = 'AppleGothic'

url = "https://movie.daum.net/ranking/reservation"
html = urllib.request.urlopen(url)
soup = BeautifulSoup(html, 'html.parser')

infos = soup.findAll('div', attrs={'class':'thumb_cont'})

# print('-' * 40)
# print(infos)
# print('-' * 40)

no = 0
result = []
for info in infos:
    no += 1
    mytitle = info.find('a', attrs={'class':'link_txt'})
    title = mytitle.string

    mygrade = info.find('span', attrs={'class':'txt_grade'})
    grade = mygrade.string

    mynum = info.find('span', attrs={'class':'txt_num'})
    num = mynum.string

    myrelease = info.find('span', attrs={'class':'txt_info'})
    release = myrelease.span.string

    result.append((no, title, grade, num, release))
# print(result)

print('-' * 40)

mycolumn = ['순위', '제목', '평점', '예매율', '개봉일']

myframe = DataFrame(result, columns=mycolumn)
newdf = myframe.set_index(keys=['순위'])
print(newdf)
print('-' * 40)

filename = 'daumMovie.csv'
myframe.to_csv(filename, encoding='utf8', index=False)
print(filename, ' saved...', sep='')
print('finished')

dfmovie = myframe.reindex(columns=['제목', '평점', '예매율'])
print(dfmovie)

mygroup0 = dfmovie['제목']
mygroup1 = dfmovie['평점']
mygroup2 = dfmovie['예매율']
mygroup2 = mygroup2.str.replace('%','')

df = pd.concat([mygroup1, mygroup2], axis=1)
df = df.set_index(mygroup0)
df.columns = ['평점', '예매율']
print(df)

df.astype(float).plot(kind='barh', title='영화별 평점과 예매율', rot=0)
filename = 'daumMovieGraph.png'
plt.savefig(filename, dpi=400, bbox_inches='tight')
plt.show()


## quiz_02_enjae.py

import urllib.request
from bs4 import BeautifulSoup
import pandas as pd
from pandas import DataFrame
import matplotlib.pyplot as plt

plt.rcParams['font.family'] = 'AppleGothic'

url = "https://movie.daum.net/ranking/reservation"
html = urllib.request.urlopen(url)
soup = BeautifulSoup(html, 'html.parser')

infos = soup.findAll('div', attrs={'class':'thumb_cont'})

# print('-' * 40)
# print(infos)
# print('-' * 40)

no = 0
result = []
for info in infos:
    no += 1
    mytitle = info.find('a', attrs={'class':'link_txt'})
    title = mytitle.string

    mygrade = info.find('span', attrs={'class':'txt_grade'})
    grade = mygrade.string

    mynum = info.find('span', attrs={'class':'txt_num'})
    num = mynum.string

    myrelease = info.find('span', attrs={'class':'txt_info'})
    release = myrelease.span.string

    result.append((no, title, grade, num, release))
# print(result)

print('-' * 40)

mycolumn = ['순위', '제목', '평점', '예매율', '개봉일']

myframe = DataFrame(result, columns=mycolumn)
newdf = myframe.set_index(keys=['순위'])
print(newdf)
print('-' * 40)

filename = 'daumMovie.csv'
myframe.to_csv(filename, encoding='utf8', index=False)
print(filename, ' saved...', sep='')
print('finished')

dfmovie = myframe.reindex(columns=['제목', '평점', '예매율'])
print(dfmovie)

mygroup0 = dfmovie['제목']
mygroup1 = dfmovie['평점']
mygroup2 = dfmovie['예매율']
mygroup2 = mygroup2.str.replace('%','')

df = pd.concat([mygroup1, mygroup2], axis=1)
df = df.set_index(mygroup0)
df.columns = ['평점', '예매율']
print(df)

df.astype(float).plot(kind='barh', title='영화별 평점과 예매율', rot=0)
filename = 'daumMovieGraph.png'
plt.savefig(filename, dpi=400, bbox_inches='tight')
plt.show()


## quiz_02_heeyeon.py

import urllib.request
from bs4 import BeautifulSoup
import pandas as pd
from pandas import DataFrame
import matplotlib.pyplot as plt

plt.rcParams['font.family'] = 'AppleGothic'

url = "https://movie.daum.net/ranking/reservation"
html = urllib.request.urlopen(url)
soup = BeautifulSoup(html, 'html.parser')

infos = soup.findAll('div', attrs={'class':'thumb_cont'})

# print('-' * 40)
# print(infos)
# print('-' * 40)

no = 0
result = []
df = pd.DataFrame()
# print(df)
for info in infos:
    no += 1
    mytitle = info.find('a', attrs={'class':'link_txt'})
    title = mytitle.string
    # print(title)

    a = info.find('span', attrs={'class':'txt_grade'})
    grade = a.string
    # print(grade)

    b = info.find('span', attrs={'class': 'txt_num'}).string.strip('%')
    num = b
    # print(num)

    c = info.find('span', attrs={'class': 'txt_info'})
    d = c.find('span', attrs={'class': 'txt_num'})
    info = d.string
    # print(info)

    result.append([no, title, grade, num, info])
    df = pd.concat([df, pd.DataFrame(result)], axis= 0)
    result = []  #중복값이 안들어갑니다.

df.columns = ['순위', '제목', '평점', '예매율', '개봉일']
df.set_index("제목", inplace=True)
print(df)
print(df.info())
#
# print(result)

newDf =df.loc[:, ['평점','예매율']]
newDf.astype(float).plot(kind='barh', rot=45,legend=True)
plt.title('다음 영화의 평점과 예매율')

filename = 'daummovie.png'
plt.savefig(filename)
print(filename, 'saved ....')


## quiz_02_jiwon.py

import pandas as pd
import urllib.request
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
from pandas import DataFrame

plt.rcParams['font.family'] = 'AppleGothic'

myurl = 'https://movie.daum.net/ranking/reservation'
html = urllib.request.urlopen(myurl)
soup = BeautifulSoup(html, 'html.parser')

mytargets = soup.findAll('div', attrs={'class':'thumb_cont'})
# print(mytargets)

no = 0
myframe = pd.DataFrame()

for target in mytargets:
    result = []
    no += 1

    mytitle = target.find('a', attrs={'class':'link_txt'})
    title = mytitle.string
    # print('제목 : ' + title)

    myscore = target.find('span', attrs={'class':'txt_grade'})
    score = myscore.string
    # print('평점 : ' + score)

    mybooked = target.find('span', attrs={'class':'txt_num'})
    booked = mybooked.string.replace('%', '')
    # print('예매율 : ' + booked)

    mydata = target.find('span', attrs={'class': 'txt_info'})
    mydata2 = mydata.find('span', attrs={'class': 'txt_num'})
    target = mydata2.string
    # print('-' * 50)

    # result.append([no, title, score, booked, target])
    result.append([title, score, booked])
    myframe = pd.concat([myframe, pd.DataFrame(result)], axis=0)

# myframe.columns = ['순위', '제목', '평점', '예매율', '개봉일']
# myframe.set_index("순위", inplace=True)
myframe.columns = ['제목', '평점', '예매율']
myframe.set_index("제목", inplace=True)

myframe.astype(float).plot(kind='barh', title='영화별 평점과 예매율', figsize=(10, 6), legend=True)
plt.show()

print(myframe)
print(myframe.info())


## quiz_02_minsub.py

import urllib.request
import pandas as pd
from bs4 import BeautifulSoup
from pandas import DataFrame
import matplotlib.pyplot as plt

url = "https://movie.daum.net/ranking/reservation"
html = urllib.request.urlopen(url)
soup = BeautifulSoup(html, 'html.parser')

infos = soup.findAll('div', attrs={'class':'thumb_cont'})

# print('-' * 40)
# print(infos)
# print('-' * 40)

no = 0
result = []
for info in infos:
    no += 1
    mytitle = info.find('a', attrs={'class':'link_txt'})
    title = mytitle.string

    mygrade = info.find('span', attrs={'class':'txt_grade'})
    grade = mygrade.string

    mynum = info.find('span', attrs={'class':'txt_num'})
    num = mynum.string

    myrelease = info.find('span', attrs={'class':'txt_info'})
    release = myrelease.span.string

    result.append((no, title, grade, num, release))
# print(result)

print('-' * 40)

mycolumn = ['순위', '제목', '평점', '예매율', '개봉일']

myframe = DataFrame(result, columns=mycolumn)
newdf = myframe.set_index(keys=['순위'])
print(newdf)
print('-' * 40)

filename = 'daumMovie.csv'
myframe.to_csv(filename, encoding='utf8', index=False)
print(filename, ' saved...', sep='')
print('finished')
####################################################################################################
plt.rcParams['font.family'] = 'AppleGothic'
myframe = pd.read_csv(filename, index_col='제목', encoding='utf-8')
myframe.index.name = '제목'
myframe['예매율'] = myframe['예매율'].str.strip('%').astype(float)
myframe[['평점', '예매율']].plot(kind='barh',color=['r', 'b'], rot=0, title='평점과 예매율')

filename = 'bs4_exam.png'
plt.savefig(filename, dpi=400, bbox_inches='tight')
print(filename + ' Saved…')
print('-' * 100)
plt.show()


## quiz_02_sanghyun.py

import pandas as pd
import matplotlib.pyplot as plt

plt.rcParams['font.family'] = 'Malgun Gothic'

filename = 'daumMovie.csv'

myframe = pd.read_csv(filename, index_col='제목', encoding='utf-8')
# myframe['평점'] = myframe['평점']
# myframe['예매율'] = myframe['예매율']

#GPT 빌린부분
myframe['평점'] = myframe['평점'].astype(float)
myframe['예매율'] = myframe['예매율'].str.replace('%', '').astype(float)

myframe[['평점', '예매율']].plot(kind='barh', rot=0, title='영화별 평점과 예매율', legend=True)
print(myframe)
print('-' * 40)

filename = 'a.png'
plt.savefig(filename, dpi=400, bbox_inches='tight')
print(filename + 'Saved...')
plt.show()



# pip install selenium   

## p340_ChickenUtil.py

import time, datetime, ssl
import pandas as pd
import urllib.request

from selenium import webdriver
from selenium.webdriver.common.by import By

from bs4 import BeautifulSoup

class ChickenStore():
    myencoding = 'utf-8'

    def getWebDriver(self, cmdJavaScript):
        # cmdJavaScript : 문자열로 구성된 자바 스크립트 커맨드
        print(cmdJavaScript)
        self.driver.execute_script(cmdJavaScript)
        wait = 5
        # self.driver.implicitly_wait(wait)
        time.sleep(wait)
        mypage = self.driver.page_source

        return BeautifulSoup(mypage, 'html.parser')

    def getSoup(self):
        if self.soup == None:
            return None
        else:
            if self.brandName != 'pelicana':
                return BeautifulSoup(self.soup, 'html.parser')
            else:  # 페리카나 # Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.
                return BeautifulSoup(self.soup, 'html.parser')
                # return BeautifulSoup(self.soup, 'html.parser', from_encoding="iso-8859-1")

    def get_request_url(self):
        request = urllib.request.Request(self.url)
        try:
            context = ssl._create_unverified_context()
            response = urllib.request.urlopen(request, context=context)
            if response.getcode() == 200:
                # print('[%s] url request success' % datetime.datetime.now())

                if self.brandName != 'pelicana':
                    return response.read().decode(self.myencoding)
                else:
                    return response

        except Exception as err:
            print(err)
            now = datetime.datetime.now()
            msg = '[%s] error for url %s' % (now, self.url)
            print(msg)
            return None

    def save2Csv(self, result):
        data = pd.DataFrame(result, columns=self.mycolumns)
        data.to_csv(self.brandName + '.csv', \
                    encoding=self.myencoding, index=True)

    def __init__(self, brandName, url):
        self.brandName = brandName
        self.url = url

        self.mycolumns = ['brand', 'store', 'sido', 'gungu', 'address']

        if self.brandName in ['pelicana']:
            self.mycolumns.append('phone')

        elif self.brandName in ['nene', 'cheogajip', 'goobne']:
            self.mycolumns.append('phone')

        else:
            pass

        if self.brandName != 'goobne':
            self.soup = self.get_request_url()
            self.driver = None
        else:  # 굽네 매장
            self.soup = None
            # filepath = 'c:/chromedriver.exe'
            filepath = '/Users/lune/chromedriver_mac64/chromedriver'
            self.driver = webdriver.Chrome(filepath)
            self.driver.get(self.url)
        # print('생성자 호출됨')
# end class ChickenStore()


## p342_countLoop.py

from itertools import count

for page_idx in count():
    if page_idx >= 5:
        break
    print(page_idx)
print('finished')


## p350_getPelicanaStore.py

from itertools import count
from p340_ChickenUtil import ChickenStore

brandName = 'pelicana'
base_url = 'https://www.pelicana.co.kr/store/stroe_search.html'

def getData():
    savedData = []

    for page_idx in count():
        url = base_url + '?page=' + str(page_idx + 1)
        # print( url )
        chknStore = ChickenStore(brandName, url)
        soup = chknStore.getSoup()

        mytable = soup.find('table', attrs={'class': 'table mt20'})
        mytbody = mytable.find('tbody')
        print(mytbody)

        shopExists = False
        for mytr in mytbody.findAll('tr'):
            shopExists = True
            mylist = list(mytr.strings)
            print(mylist)

            imsiphone = mytr.select_one('td:nth-of-type(3)').string
            if imsiphone != None:
                phone = imsiphone.strip()
            else:
                phone = ""
            
            store = mylist[1]
            address = mylist[3]

            if len(address) >= 2:
                imsi = address.split()
                sido = imsi[0]
                gungu = imsi[1]

            mydata = [brandName, store, sido, gungu, address, phone]
            savedData.append(mydata)

        if shopExists == False:
            chknStore.save2Csv(savedData)
            break

print(brandName + ' 매장 크롤링 시작')
getData()
print(brandName + ' 매장 크롤링 끝')


## Ubuntu에서..

# pip install pandas

# pip install numpy

# pip install selenium 

# apt -y install python3-bs4

# python p350_getPelicanaStore.py


## p360_getCheogajlpStore.py

from itertools import count
from p340_ChickenUtil import ChickenStore

brandName = 'cheogajip'
base_url = 'https://www.cheogajip.co.kr/bbs/board.php'

def getData():
    savedData = []

    for page_idx in count():
        if page_idx >= 125:
            chknStore.save2Csv(savedData)
            break
        else:
            url = base_url
            url += '?bo_table=store'
            url += '&page=%s' % str(page_idx+1)
            # print( url )
            
            chknStore = ChickenStore(brandName, url)
            soup = chknStore.getSoup()

            mytbody = soup.find('tbody')
            # print(mytbody)

            shopExists = False
            for mytr in mytbody.findAll('tr'):
                shopExists = True
                mylist = list(mytr.strings)
                print(mylist)

                store = mylist[1]
                address = mylist[3]
                phone = mylist[5]
    
                if len(address) >= 2:
                    imsi = address.split()
                    sido = imsi[0]
                    gungu = imsi[1]

                mydata = [brandName, store, sido, gungu, address, phone]
                print(mydata)
                savedData.append(mydata)

print(brandName + ' 매장 크롤링 시작')
getData()
print(brandName + ' 매장 크롤링 끝')


## ChromeDriver 허용 방법

# xattr -d com.apple.quarantine /Users/lune/chromedriver_mac64/chromedriver


## p368_seleniumTest.py

import time
from selenium import webdriver
from selenium.webdriver.common.by import By

driver = webdriver.Chrome()
print(type(driver))
print('-' * 50)

print('Go Google~!!')
url = 'http://www.google.com'
driver.get(url)

search_textbox = driver.find_element(By.NAME, 'q')

word = '북미정상회담'
search_textbox.send_keys(word)

search_textbox.submit()

wait = 3
print(str(wait) + '동안 기다립니다.')
time.sleep(wait)

imagefile = 'xx_capture.png'
driver.save_screenshot(imagefile)
print(imagefile + ' 이미지 저장')

wait = 3
driver.implicitly_wait(wait)

driver.quit()
print('Browser Exit~!!')


## android.csv

name,value
kim,100
lee,200


## iphone.csv

name,value
choi,300
park,400


## p379_concatTest.py

import pandas as pd

afile = 'android.csv'
bfile = 'iphone.csv'

atable = pd.read_csv(afile, encoding='utf-8')
btable = pd.read_csv(bfile, encoding='utf-8')

print(atable)
print('-' * 50)
print(btable)
print('-' * 50)

atable['phone']='안드로이드'
btable['phone']='아이폰'

mylist = []
mylist.append(atable)
mylist.append(btable)
result = pd.concat(objs=mylist, axis=0, ignore_index=True)
print(result)
filename = 'result.csv'
result.to_csv(filename, encoding='utf-8')
print(filename+' saved...')


## Quiz_03.py (pelicana.csv + cheogajip.csv)

import pandas as pd

afile = 'cheogajip.csv'
bfile = 'pelicana.csv'

atable = pd.read_csv(afile, index_col=0, header=0, encoding='utf-8')
btable = pd.read_csv(bfile, index_col=0, header=0, encoding='utf-8')

print(atable)
print('-' * 50)
print(btable)
print('-' * 50)

mylist = []
mylist.append(atable)
mylist.append(btable)
result = pd.concat(objs=mylist, axis=0, ignore_index=True)
print(result)
filename = 'ChickenResult.csv'
result.to_csv(filename, encoding='utf-8')
print(filename+' saved...')


## p384_mergeTest.py

import pandas as pd

mystorefile = 'store.csv'
mystore = pd.read_csv(mystorefile, encoding='utf-8', index_col=0, header=0)
print('\n매장 테이블')
print(mystore)

districtfile = 'districtmini.csv'
district = pd.read_csv(districtfile, encoding='utf-8', index_col=0, header=0)
print('\n행정구역 테이블')
print(district)

result = pd.merge(mystore, district, on=['sido','gungu'], how='outer', suffixes=['','_'], indicator=True)
print('\nMerge Result')
print(result)

m_result = result.query('_merge == "left_only"')
print('\n좌측에만 있는 행')
print(m_result)

gungufile = open('./gungufile.txt', encoding='utf-8')
gungu_list = gungufile.readlines()

gungu_dict = {}
for onegu in gungu_list:
    mydata = onegu.replace('\n', '').split(':')
    gungu_dict[mydata[0]] = mydata[1]
print('\n군구 사전 내용')
print(gungu_dict)

mystore.gungu = mystore.gungu.apply(lambda data : gungu_dict.get(data, data))

print('\n수정된 가게 정보 출력')
print(mystore)


## Ex_p352_01.py

import pandas as pd

afile = 'data03.csv'
bfile = 'data04.csv'

atable = pd.read_csv(afile, header=0, encoding='utf-8')
btable = pd.read_csv(bfile, header=None, encoding='utf-8', names=['이름','성별','국어','영어','수학'])

print(atable)
print('-' * 40)
print(btable)
print('-' * 40)

atable['반'] = '1반'
btable['반'] = '2반'

mylist = []
mylist.append(atable)
mylist.append(btable)

result = pd.concat(objs=mylist, axis=0, ignore_index=True)
print(result)
print('-' * 40)

dropIndex = result[result['이름'] == '심형식'].index
print(dropIndex)
print('-' * 40)

newResult = result.drop(dropIndex)
print(newResult)
print('-' * 40)

filename = 'result.csv'
newResult.to_csv(filename, encoding='utf-8')
print(filename + ' saved...')


## Ex_p352_02.py

import pandas as pd
from pandas import DataFrame

dict1 = {'name':['김유신', '김유신', '이순신', '박영효', '이순신', '이순신', '김유신'], 'korean': [60, 50, 40, 80, 30, 55, 45]}
df1 = DataFrame(dict1)

dict2 = {'name':['이순신', '김유신', '신사임당'], 'english':[60, 55, 80]}
df2 = DataFrame(dict2)

print('\n# DataFrame 출력 01')
print(df1)

print('\n# DataFrame 출력 02')
print(df2)

print('\n# merge() 메소드의 on="name"을 이용하여 데이터 합치기')
print(pd.merge(df1, df2, on='name'))
print('\n# merge() 메소드의 how="outer"을 이용하여 데이터 합치기')
print(pd.merge(df1, df2, how='outer'))




